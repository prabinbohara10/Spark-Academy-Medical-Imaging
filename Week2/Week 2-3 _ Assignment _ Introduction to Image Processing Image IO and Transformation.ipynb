{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Week3Assignement.ipynb","provenance":[{"file_id":"11l_IZ7UJPXfY_2-evj6bDGc0BtLp5tJH","timestamp":1655414498020},{"file_id":"1El2EOZ5I9kv3GKsNEHW9UqjQb34DCADT","timestamp":1655413205440},{"file_id":"1ADRRg_BOSFyTFnb4PwAFQTTg7-biNa28","timestamp":1655322309206}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Week 3 Introduction to image processing assignment"],"metadata":{"id":"i1jC0a9JPdXV"}},{"cell_type":"markdown","source":["# importing the required libraries"],"metadata":{"id":"eFMMkuVbTk-1"}},{"cell_type":"code","source":["!pip install pydicom\n","import pydicom\n","import numpy as np \n","import glob \n","import os\n","import matplotlib.pyplot as plt\n","import json \n","from ipywidgets import interact, interactive\n","from typing import List, Tuple, Union"],"metadata":{"id":"BQO2PIXmFIIu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655443110101,"user_tz":360,"elapsed":12396,"user":{"displayName":"keyhan najafian","userId":"02246850680582407601"}},"outputId":"d7f2f308-98b9-4d6d-b14b-3a996264d03b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydicom\n","  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 6.8 MB/s \n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.3.0\n"]}]},{"cell_type":"markdown","source":["# downloading the data\n","#### In this section we are going to download a public dataset and unzip it for later usage. "],"metadata":{"id":"-kMpNRj9Tnuw"}},{"cell_type":"code","source":["! wget --no-check-certificate https://data.idoimaging.com/dicom/1010_brain_mr/1010_brain_mr_04_lee.zip\n","! unzip 1010_brain_mr_04_lee.zip"],"metadata":{"id":"U9R1LNF9VdFf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655443115086,"user_tz":360,"elapsed":812,"user":{"displayName":"keyhan najafian","userId":"02246850680582407601"}},"outputId":"8c071c63-617e-46ac-f5ed-22f36361fa6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-17 05:18:34--  https://data.idoimaging.com/dicom/1010_brain_mr/1010_brain_mr_04_lee.zip\n","Resolving data.idoimaging.com (data.idoimaging.com)... 52.84.52.46, 52.84.52.23, 52.84.52.6, ...\n","Connecting to data.idoimaging.com (data.idoimaging.com)|52.84.52.46|:443... connected.\n","WARNING: cannot verify data.idoimaging.com's certificate, issued by ‘CN=Amazon,OU=Server CA 1B,O=Amazon,C=US’:\n","  Issued certificate has expired.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2212367 (2.1M) [application/zip]\n","Saving to: ‘1010_brain_mr_04_lee.zip’\n","\n","1010_brain_mr_04_le 100%[===================>]   2.11M  --.-KB/s    in 0.08s   \n","\n","2022-06-17 05:18:34 (26.7 MB/s) - ‘1010_brain_mr_04_lee.zip’ saved [2212367/2212367]\n","\n","Archive:  1010_brain_mr_04_lee.zip\n","   creating: 1010_brain_mr_04_lee/\n","  inflating: 1010_brain_mr_04_lee/img_000.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_001.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_002.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_003.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_004.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_005.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_006.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_007.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_008.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_009.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_010.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_011.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_012.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_013.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_014.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_015.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_016.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_017.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_018.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_019.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_020.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_021.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_022.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_023.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_024.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_025.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_026.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_027.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_028.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_029.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_030.dcm  \n","  inflating: 1010_brain_mr_04_lee/img_031.dcm  \n"]}]},{"cell_type":"code","source":["dir_path = '1010_brain_mr_04_lee'"],"metadata":{"id":"OIzLZyKxFB_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Excercise 1: Read Dicom files from a directory. \n","For this question, you need to read all the `.dcm` files inside the provided directory slice by slice, and return the loaded slices in a format of a single `Numpy List` variable. \n","\n","* Define a function for reading the DICOM files and sort them based on their `instance numbers`\n","* Access the patient ID from the dicom object using the following ways and print them: \n","  - indexing \n","  - attributes (tags)"],"metadata":{"id":"mexiti9ZTqbr"}},{"cell_type":"code","source":["# solution\n","def load_dicom_slices(dir_path: str, force: bool=False):\n","  \"\"\" Load and sort a series of dicom files inside the provided folder path. \n","  \"\"\"\n","  # Your code here. \n","  return slices\n","\n","slices = load_dicom_slices(dir_path)\n","print(\"Number of slices: \", len(slices))\n","print('Slices dtype: ', type(slices[0]))"],"metadata":{"id":"_tTsBRxDATK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Viewing slices shape. \n","print(\"Volume Shape (Row, Column): \", slices[0].Rows, slices[0].Rows)"],"metadata":{"id":"Q65yRCc8HfHN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# interactive slides for viewing dicom slides\n","plt.figure(1, figsize=(10, 10))\n","def dicom_animation(x):\n","    plt.imshow(slices[x].pixel_array, cmap=plt.cm.bone)\n","    plt.colorbar()\n","    return x\n","\n","interact(dicom_animation, x=(0, len(slices)-1))"],"metadata":{"id":"AenqwpH7fHkW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Accessing the patient id. \n","# Your code here. "],"metadata":{"id":"90vp7XOST5k9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: \n","#### For this exercise you need to implement four function and try applying them on the loaded slices. \n","* Define a function named `to_hu` for transforming the slices into Hounsfield scale. \n","* Define a function named `window_clip` for cliping the pixel intensity range of each slice using a single center and windows width. Defined window describes your interested intensity range. \n","* Define a function named `to_3d_numpy` to convert all the slices into a single Numpy ndarray image. This function is able to change the datatype of the output image if the user likes to change the new image datatype. \n","* Define a function named `min_max_scaler` to scale a Numpy array into range `0` and `1` for easier visualization with matplotlib. This function is able to change the datatype (optional dtype by user) of the output image to `float`. \n","\n"],"metadata":{"id":"zY1MJ-r8MwM-"}},{"cell_type":"code","source":["def to_hu(slices: List):\n","    \"\"\"Transform a list of slices to a Hounsfield Unit Scale. \n","    This function takes the loaded slices and return a list of transformed Numpy array format slices. \n","    \"\"\"\n","    hu_slices = []\n","    intercept = slices[0].RescaleIntercept if 'RescaleIntercept' in slices[0] else 0\n","    slope = slices[0].RescaleSlope if 'RescaleSlope' in slices[0] else 1\n","    for sli in slices: \n","        # Your code here. \n","    return hu_slices\n","\n","def window_clip(slices: List, window_cent: int, window_width: int):\n","    \"\"\"Clip a list of slices pixels, one by one, into a specific intensity range based on the provided window location and size.\n","    All the pixels inside each single slice with a intensity below and over the window range will be clipped into the min and max intensity range window covers. \n","    This function returns a list of clipped Numpy array slices. \n","    \"\"\"\n","    min_val = window_cent - window_width // 2\n","    max_val = window_cent + window_width // 2\n","    cliped_slices = []\n","    for sli in slices: \n","        # Your code here. \n","    return cliped_slices\n","\n","def to_3d_numpy(slices: List, dtype=None): \n","    \"\"\"Stack up all slices into a single NumPy array of the provided data type.\n","    \"\"\"\n","    # Your code here. \n","    return image\n","\n","def min_max_scaler(image: np.ndarray, dtype: Union[type, None]=None): \n","    \"\"\"Scale a single Numpy array image intensity into range `0` and `1`\n","    \"\"\"\n","    # Your code here. \n","    return image\n","\n","def visualizer(slice: np.ndarray, title= ''): \n","    \"\"\"Visualize a slice of type numpy array with the provided title.\"\"\"\n","    plt.imshow(slice, cmap=plt.cm.bone)\n","    plt.title(title)\n","    plt.show()"],"metadata":{"id":"DpThAREoMvS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["processed_slices_hu = to_hu(slices)\n","processed_slices_cliped = window_clip(processed_slices_hu, 500, 1000) # Extracting soft tissues. \n","image = to_3d_numpy(processed_slices_cliped, dtype=None)\n","\n","print('Numpy array image shape is: ', image.shape)\n","print('Transformed image pixel value range (min, max): ', (image.min(), image.max()))\n","\n","scaled_image = min_max_scaler(image, dtype=np.float32)\n","print('Scaled image pixel value range (min, max): ', (scaled_image.min(), scaled_image.max()))\n","\n","# You can see the scaled version of your slected region using the `window_clip` function here.\n","visualizer(processed_slices_hu[10], 'HU transform')\n","visualizer(scaled_image[10], 'Scaled')"],"metadata":{"id":"YU7TcJkCW7dr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Saving the data in numpy format\n","* Convert original frames into a numpy image array without any preprocessing, and save it as a single `.npy` file named `original_numpy_version.npy`. Keeping the original slices as a 3d numpy sample in case we needed it in the future.\n","* Create an ouput folder named `scaled_slices` and save all the scaled slices one by one into the folder. Assign a unique name to each slice while you are keeping the original order. "],"metadata":{"id":"vPSuaw6NZ1nw"}},{"cell_type":"code","source":["# Convert the original slices into a 3d nmpy array and save it as a .npy file format. \n","# Your code here. "],"metadata":{"id":"oRmK9A3b6y7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a folder and save the scaled slices one by one. \n","# Your code here. "],"metadata":{"id":"Uri1gESq6y9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: Save the processed numpy data as a series of DICOM files\n","#### In this section, you need to save the scaled version image of the loaded dicom slices into a series of dicom files inside a directory named `scaled_slices_dicom`, be splitting the image into a sequence of slices in the original order.  \n","To do so, you need to create a new dicom dataset for each slide, import the original dicom information into the new created dataset, and save it with a unique name inside the mentioned directory."],"metadata":{"id":"TO1Z0iab_W-S"}},{"cell_type":"code","source":["from pydicom.dataset import Dataset, FileDataset\n","from pydicom.uid import ExplicitVRLittleEndian\n","import pydicom._storage_sopclass_uids\n","\n","os.makedirs('scaled_slices_dicom', exist_ok=True)\n","\n","# Your code here."],"metadata":{"id":"Y3MscdDjKkBQ"},"execution_count":null,"outputs":[]}]}